{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 불러오기\n",
    "data = pd.read_csv('azdigar nav sartirovka+0 delete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석할 열들\n",
    "columns = [\n",
    "    'w08chronic_a', 'w08chronic_b', 'w08chronic_c',\n",
    "    'w08chronic_d', 'w08chronic_e', 'w08chronic_f',\n",
    "    'w08chronic_g', 'w08chronic_h', 'w08chronic_i',\n",
    "    'w08chronic_k', 'w08chronic_l', 'w08chronic_m'\n",
    "] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 클리닝 - 'w08chronic_m'에서 값이 3인 행 제거\n",
    "cleaned_data = data[data['w08chronic_m'] != 3] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 피처 데이터 정의 (모든 chronic 컬럼 제외)\n",
    "X = cleaned_data.drop(columns=columns)\n",
    "y_all = cleaned_data[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델 정의\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 유전 알고리즘 파라미터 설정\n",
    "population_size = 100  # 개체군 크기 (작게 설정하여 실행 시간 단축)\n",
    "num_generations = 100  # 세대 수 (작게 설정하여 실행 시간 단축)\n",
    "mutation_rate = 0.1  # 돌연변이 확률\n",
    "\n",
    "# 초기 개체군 생성\n",
    "def initialize_population():\n",
    "    return [np.random.randint(2, size=X_scaled.shape[1]).tolist() for _ in range(population_size)]\n",
    "\n",
    "# 적합도 평가 함수\n",
    "def fitness_function(individual, model, X_train, y_train, X_test, y_test):\n",
    "    selected_features = [i for i, bit in enumerate(individual) if bit]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # 피처가 선택되지 않으면 적합도는 0\n",
    "    \n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "    X_test_selected = X_test[:, selected_features]\n",
    "    \n",
    "    try:\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        \n",
    "        # 타겟 클래스가 두 개 이상이면 AUC 계산을 위해 타겟을 이진화 (One-vs-Rest 방식)\n",
    "        y_test_bin = label_binarize(y_test, classes=np.unique(y_train))\n",
    "        if y_test_bin.shape[1] == 1:  # 클래스가 하나인 경우\n",
    "            y_test_bin = np.concatenate([1 - y_test_bin, y_test_bin], axis=1)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        auc = roc_auc_score(y_test_bin, model.predict_proba(X_test_selected), multi_class=\"ovr\", average=\"macro\")\n",
    "        \n",
    "        return f1  # 적합도는 F1 점수로 설정\n",
    "    except Exception as e:\n",
    "        print(f\"적합도 평가 중 오류 발생: {e}\")\n",
    "        return 0\n",
    "\n",
    "# 개체군 선택 함수\n",
    "def selection(population, model, X_train, y_train, X_test, y_test):\n",
    "    scores = [fitness_function(ind, model, X_train, y_train, X_test, y_test) for ind in population]\n",
    "    # 상위 절반 선택\n",
    "    selected_indices = np.argsort(scores)[-population_size // 2:]\n",
    "    return [population[i] for i in selected_indices]\n",
    "\n",
    "# 교차 함수\n",
    "def crossover(parent1, parent2):\n",
    "    crossover_point = random.randint(1, len(parent1) - 1)\n",
    "    child1 = parent1[:crossover_point] + parent2[crossover_point:]\n",
    "    child2 = parent2[:crossover_point] + parent1[crossover_point:]\n",
    "    return child1, child2\n",
    "\n",
    "# 돌연변이 함수\n",
    "def mutate(individual):\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < mutation_rate:\n",
    "            individual[i] = 1 - individual[i]  # 비트 반전\n",
    "    return individual\n",
    "\n",
    "# 유전 알고리즘 실행 함수\n",
    "def run_genetic_algorithm(model, X_train, y_train, X_test, y_test):\n",
    "    population = initialize_population()\n",
    "    best_individual = None\n",
    "    best_f1 = -1\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        print(f\"Generation {generation + 1}/{num_generations}\")  # 진행 상황 출력\n",
    "        selected_population = selection(population, model, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        children = []\n",
    "        while len(children) < population_size - len(selected_population):\n",
    "            parent1, parent2 = random.sample(selected_population, 2)\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            child1 = mutate(child1)\n",
    "            child2 = mutate(child2)\n",
    "            children.extend([child1, child2])\n",
    "        \n",
    "        # 새로운 개체군 구성\n",
    "        population = selected_population + children[:population_size - len(selected_population)]\n",
    "        \n",
    "        # 현재 세대에서 최고의 개체 찾기\n",
    "        for ind in population:\n",
    "            current_f1 = fitness_function(ind, model, X_train, y_train, X_test, y_test)\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1 = current_f1\n",
    "                best_individual = ind\n",
    "\n",
    "    return best_individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 결과 저장을 위한 빈 데이터프레임 생성\n",
    "result_table = pd.DataFrame(columns=[\n",
    "    'Target', 'Model', 'Precision', 'Recall', 'F1-Score', \n",
    "    'Accuracy', 'Micro F1', 'Macro F1', 'Weighted F1', 'AUC'\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[w08chronic_a] 열을 예측:\n",
      "==================================\n",
      "\n",
      "[Random Forest] 모델 평가:\n",
      "--------------------------\n",
      "Generation 1/100\n",
      "Generation 2/100\n",
      "Generation 3/100\n",
      "Generation 4/100\n",
      "Generation 5/100\n",
      "Generation 6/100\n",
      "Generation 7/100\n",
      "Generation 8/100\n",
      "Generation 9/100\n",
      "Generation 10/100\n",
      "Generation 11/100\n",
      "Generation 12/100\n",
      "Generation 13/100\n",
      "Generation 14/100\n",
      "Generation 15/100\n",
      "Generation 16/100\n",
      "Generation 17/100\n",
      "Generation 18/100\n",
      "Generation 19/100\n",
      "Generation 20/100\n",
      "Generation 21/100\n",
      "Generation 22/100\n",
      "Generation 23/100\n",
      "Generation 24/100\n",
      "Generation 25/100\n",
      "Generation 26/100\n",
      "Generation 27/100\n",
      "Generation 28/100\n",
      "Generation 29/100\n",
      "Generation 30/100\n",
      "Generation 31/100\n",
      "Generation 32/100\n",
      "Generation 33/100\n",
      "Generation 34/100\n",
      "Generation 35/100\n",
      "Generation 36/100\n",
      "Generation 37/100\n",
      "Generation 38/100\n",
      "Generation 39/100\n",
      "Generation 40/100\n",
      "Generation 41/100\n",
      "Generation 42/100\n",
      "Generation 43/100\n",
      "Generation 44/100\n",
      "Generation 45/100\n",
      "Generation 46/100\n",
      "Generation 47/100\n",
      "Generation 48/100\n",
      "Generation 49/100\n",
      "Generation 50/100\n",
      "Generation 51/100\n",
      "Generation 52/100\n",
      "Generation 53/100\n",
      "Generation 54/100\n",
      "Generation 55/100\n",
      "Generation 56/100\n",
      "Generation 57/100\n",
      "Generation 58/100\n",
      "Generation 59/100\n",
      "Generation 60/100\n",
      "Generation 61/100\n",
      "Generation 62/100\n",
      "Generation 63/100\n",
      "Generation 64/100\n",
      "Generation 65/100\n"
     ]
    }
   ],
   "source": [
    "# 8. 각 타겟 열을 사용한 학습 및 평가\n",
    "for target_column in columns:\n",
    "    print(f'\\n[{target_column}] 열을 예측:')\n",
    "    print('==================================')\n",
    "\n",
    "    y = cleaned_data[target_column].values\n",
    "\n",
    "    # 데이터 나누기\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # 9. 각 모델에 대해 학습 및 평가\n",
    "    for model_name, model in models.items():\n",
    "        print(f'\\n[{model_name}] 모델 평가:')\n",
    "        print('--------------------------')\n",
    "\n",
    "        try:\n",
    "            # 유전 알고리즘을 사용한 피처 선택\n",
    "            best_individual = run_genetic_algorithm(model, X_train, y_train, X_test, y_test)\n",
    "            selected_features = [i for i, bit in enumerate(best_individual) if bit]\n",
    "\n",
    "            if len(selected_features) == 0:\n",
    "                print(f'선택된 피처가 없습니다. {target_column} 열에 대한 {model_name} 모델 평가를 건너뜁니다.')\n",
    "                continue\n",
    "\n",
    "            X_train_selected = X_train[:, selected_features]\n",
    "            X_test_selected = X_test[:, selected_features]\n",
    "\n",
    "            # 타겟 클래스가 두 개 이상이면 AUC 계산을 위해 타겟을 이진화 (One-vs-Rest 방식)\n",
    "            y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "            if y_test_bin.shape[1] == 1:  # 클래스가 하나인 경우\n",
    "                y_test_bin = np.concatenate([1 - y_test_bin, y_test_bin], axis=1)\n",
    "\n",
    "            # 모델 학습\n",
    "            model.fit(X_train_selected, y_train)\n",
    "\n",
    "            # 예측\n",
    "            y_pred = model.predict(X_test_selected)\n",
    "\n",
    "            # 확률 예측 값이 있는 경우\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_pred_proba = model.predict_proba(X_test_selected)\n",
    "            else:\n",
    "                y_pred_proba = np.zeros((len(y_test), len(np.unique(y_test))))  # 확률 값을 지원하지 않는 모델에 대한 처리\n",
    "\n",
    "            # 정확도 계산\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # precision, recall, f1-score 계산 (weighted average)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                y_test, y_pred, average='weighted'\n",
    "            )\n",
    "\n",
    "            # Micro, Macro, Weighted F1 계산\n",
    "            micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "            macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            weighted_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "            # AUC 계산\n",
    "            try:\n",
    "                auc = roc_auc_score(\n",
    "                    y_test_bin, y_pred_proba, multi_class=\"ovr\", average='weighted'\n",
    "                )\n",
    "            except ValueError:\n",
    "                auc = np.nan\n",
    "\n",
    "            # 결과 추가\n",
    "            new_row = pd.DataFrame({\n",
    "                'Model': [model_name],\n",
    "                'Target': [target_column],\n",
    "                'Precision': [precision],\n",
    "                'Recall': [recall],\n",
    "                'F1-Score': [f1],\n",
    "                'Accuracy': [accuracy],\n",
    "                'Micro F1': [micro_f1],\n",
    "                'Macro F1': [macro_f1],\n",
    "                'Weighted F1': [weighted_f1],\n",
    "                'AUC': [auc]\n",
    "            })\n",
    "            result_table = pd.concat([result_table, new_row], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{model_name} 모델에서 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체 모델 평가 결과:\n",
      "          Target          Model  Precision    Recall  F1-Score  Accuracy  \\\n",
      "0   w08chronic_a  Random Forest   0.761762  0.743929  0.741513  0.743929   \n",
      "1   w08chronic_a  Decision Tree   0.679258  0.678808  0.678933  0.678808   \n",
      "2   w08chronic_b  Random Forest   0.718118  0.770419  0.693542  0.770419   \n",
      "3   w08chronic_b  Decision Tree   0.748468  0.742826  0.745494  0.742826   \n",
      "4   w08chronic_c  Random Forest   0.859611  0.927152  0.892105  0.927152   \n",
      "5   w08chronic_c  Decision Tree   0.881764  0.863135  0.872003  0.863135   \n",
      "6   w08chronic_d  Random Forest   0.941285  0.970199  0.955523  0.970199   \n",
      "7   w08chronic_d  Decision Tree   0.950434  0.945916  0.948131  0.945916   \n",
      "8   w08chronic_e  Random Forest   0.943428  0.971302  0.957163  0.971302   \n",
      "9   w08chronic_e  Decision Tree   0.951336  0.938190  0.944498  0.938190   \n",
      "10  w08chronic_f  Random Forest   0.906151  0.895143  0.846700  0.895143   \n",
      "11  w08chronic_f  Decision Tree   0.843226  0.834437  0.838689  0.834437   \n",
      "12  w08chronic_g  Random Forest   0.932738  0.947020  0.924279  0.947020   \n",
      "13  w08chronic_g  Decision Tree   0.922173  0.902870  0.911734  0.902870   \n",
      "14  w08chronic_h  Random Forest   0.954796  0.952539  0.931406  0.952539   \n",
      "15  w08chronic_h  Decision Tree   0.927496  0.928256  0.927874  0.928256   \n",
      "16  w08chronic_i  Random Forest   0.766041  0.779249  0.762000  0.779249   \n",
      "17  w08chronic_i  Decision Tree   0.720452  0.725166  0.722605  0.725166   \n",
      "18  w08chronic_k  Random Forest   0.971508  0.985651  0.978529  0.985651   \n",
      "19  w08chronic_k  Decision Tree   0.974938  0.969095  0.971940  0.969095   \n",
      "20  w08chronic_l  Random Forest   0.973685  0.986755  0.980177  0.986755   \n",
      "21  w08chronic_l  Decision Tree   0.982104  0.974614  0.978011  0.974614   \n",
      "22  w08chronic_m  Random Forest   0.992333  0.992274  0.989284  0.992274   \n",
      "23  w08chronic_m  Decision Tree   0.991806  0.992274  0.992018  0.992274   \n",
      "\n",
      "    Micro F1  Macro F1  Weighted F1       AUC  \n",
      "0   0.743929  0.742392     0.741513  0.800788  \n",
      "1   0.678808  0.678479     0.678933  0.678718  \n",
      "2   0.770419  0.489649     0.693542  0.699622  \n",
      "3   0.742826  0.645339     0.745494  0.648607  \n",
      "4   0.927152  0.481100     0.892105  0.612617  \n",
      "5   0.863135  0.560008     0.872003  0.570184  \n",
      "6   0.970199  0.492437     0.955523  0.651645  \n",
      "7   0.945916  0.570770     0.948131  0.577234  \n",
      "8   0.971302  0.492721     0.957163  0.580004  \n",
      "9   0.938190  0.559721     0.944498  0.576267  \n",
      "10  0.895143  0.482612     0.846700  0.630048  \n",
      "11  0.834437  0.585711     0.838689  0.590625  \n",
      "12  0.947020  0.524825     0.924279  0.679637  \n",
      "13  0.902870  0.613309     0.911734  0.640797  \n",
      "14  0.952539  0.530372     0.931406  0.654949  \n",
      "15  0.928256  0.615969     0.927874  0.614750  \n",
      "16  0.779249  0.690066     0.762000  0.803889  \n",
      "17  0.725166  0.655680     0.722605  0.653052  \n",
      "18  0.985651  0.496387     0.978529  0.540744  \n",
      "19  0.969095  0.554635     0.971940  0.567405  \n",
      "20  0.986755  0.496667     0.980177  0.777731  \n",
      "21  0.974614  0.645051     0.978011  0.699385  \n",
      "22  0.992274  0.609170     0.989284  0.842358  \n",
      "23  0.992274  0.764719     0.992018  0.748330  \n"
     ]
    }
   ],
   "source": [
    "# 11. 결과 테이블 출력\n",
    "print(\"\\n전체 모델 평가 결과:\")\n",
    "print(result_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
